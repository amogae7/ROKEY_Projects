import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import Point, PointStamped
from std_msgs.msg import String, Bool
from visualization_msgs.msg import Marker
from cv_bridge import CvBridge
import cv2
import numpy as np
from ultralytics import YOLO
import torch
import os
import sys

# Windows OSì—ì„œëŠ” CV2.imshowì™€ ROS spinì´ ì˜ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
# Linux í™˜ê²½ì„ ê°€ì •í•˜ê³  ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

class YoloMapTransformNode(Node):
    def __init__(self):
        super().__init__('yolo_map_transform_node')
        
        # ==========================================
        # [ì„¤ì • 1] ëª¨ë¸ ë¡œë“œ ë° CUDA í™•ì¸
        # ==========================================
        home_dir = os.path.expanduser('~')
        model_path = os.path.join(home_dir, 'rokey_ws/src/cam_transform/best_yolo8s.pt')
        
        if os.path.exists(model_path):
            self.model = YOLO(model_path)
        else:
            self.model = YOLO('yolov8n.pt') 
            self.get_logger().warn("âš ï¸ ëª¨ë¸ íŒŒì¼ ì—†ìŒ. ê¸°ë³¸ yolov8n.pt ì‚¬ìš©")

        if torch.cuda.is_available():
            self.model.to('cuda')
            self.get_logger().info("CUDA ê°€ì† ì‚¬ìš© ê°€ëŠ¥ (GPU)")
        
        # ==========================================
        # [ì„¤ì • 2] ëª©ì  ì¢Œí‘œ (SLAM ë§µ ì‹¤ì œ ì¢Œí‘œ - ê¸°ë‘¥ ë°”ë‹¥ë©´)
        # ==========================================
        # ë§µì—ì„œ ì°ì€ ê¸°ë‘¥ì˜ 4ê°œ ì½”ë„ˆ ì¢Œí‘œ [ì•, ì¢Œ, ìš°, ë’¤]
        self.dst_points = np.float32([
            [-2.00,  0.4790],   # ì• (Front)
            [-1.56,  0.4990],   # ì¢Œ (Left)
            [-1.98,  0.0161],   # ìš° (Right)
            [-1.51,  0.0266]    # ë’¤ (Back)
        ])

        # ==========================================
        # [ë³€ìˆ˜ 1] ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ ê´€ë¦¬
        # ==========================================
        self.calib_step = 0              # 0: ë†’ì´ì¸¡ì •, 1: 4ì í´ë¦­, 2: ì™„ë£Œ
        self.height_vector = np.array([0, 0]) # [dx, dy]
        self.temp_pt = None              # ì„ì‹œ ì €ì¥ìš© (ë†’ì´ ì¸¡ì • ì‹œ ìœ—ë©´ ì¢Œí‘œ)
        self.clicked_points = []         # ì‚¬ìš©ìê°€ í´ë¦­í•œ ìœ—ë©´ 4ì  ì €ì¥ìš©
        self.homography_matrix = None
        self.click_order = ["ì•(Front)", "ì¢Œ(Left)", "ìš°(Right)", "ë’¤(Back)"] 
        self.cv_window_name = "YOLO & Calibration"
        
        # ==========================================
        # [ë³€ìˆ˜ 2] ROS í†µì‹  ë° ê¸°íƒ€ ì„¤ì •
        # ==========================================
        self.bridge = CvBridge()
        self.enabled = True
        self.frame_count = 0
        self.skip_frames = 1
        
        # ROS í†µì‹  ì„¤ì • (Subscriber)
        self.image_sub = self.create_subscription(Image, '/image_raw', self.image_callback, 10)
        self.enable_sub = self.create_subscription(Bool, '/yolo/enable', self.enable_callback, 10)

        # Publisher (7ê°œ í† í”½)
        self.image_pub = self.create_publisher(Image, '/yolo_sub/detection_image', 10)
        self.center_pub = self.create_publisher(Point, '/yolo_sub/detection_centers', 10)
        self.label_pub = self.create_publisher(String, '/yolo_sub/detection_labels', 10)
        self.car_pub = self.create_publisher(Bool, '/yolo/car_detected', 10)
        self.map_point_pub = self.create_publisher(PointStamped, '/yolo/map_point', 10)
        self.marker_pub = self.create_publisher(Marker, '/yolo/marker', 10)

        self.get_logger().info("ğŸš€ ë…¸ë“œ ì‹œì‘! [Step 1] ê¸°ë‘¥ì˜ ë†’ì´ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ì„¸ìš”.")

    def enable_callback(self, msg: Bool):
        self.enabled = msg.data

    def mouse_callback(self, event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            # Step 1: ë†’ì´ ì¸¡ì • (Top -> Bottom í´ë¦­)
            if self.calib_step == 0:
                if self.temp_pt is None:
                    self.temp_pt = (x, y) # ìœ—ë©´ í´ë¦­
                    self.get_logger().info("â˜ï¸ ìœ—ë©´ í´ë¦­ë¨. ì´ì œ ìˆ˜ì§ ì•„ë˜ ë°”ë‹¥ì„ í´ë¦­í•˜ì„¸ìš”.")
                else:
                    # ë°”ë‹¥ í´ë¦­ -> ë†’ì´ ë²¡í„° ê³„ì‚°
                    dx = x - self.temp_pt[0]
                    dy = y - self.temp_pt[1]
                    self.height_vector = np.array([dx, dy], dtype=np.float32)
                    self.calib_step = 1
                    self.temp_pt = None
                    self.get_logger().info(f"ğŸ“ ë†’ì´ ë³´ì •ê°’ ê³„ì‚° ì™„ë£Œ: x={dx}, y={dy}. 4ì  í´ë¦­ ì‹œì‘.")

            # Step 2: ìœ—ë©´ 4ì  í´ë¦­
            elif self.calib_step == 1:
                if len(self.clicked_points) < 4:
                    self.clicked_points.append([x, y])
                    self.get_logger().info(f"ğŸ–±ï¸ í´ë¦­ {len(self.clicked_points)}/4: ({x}, {y})")

    def image_callback(self, msg):
        if not self.enabled:
            return
        
        try:
            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            
            # ==========================================
            # ëª¨ë“œ 1: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ (Step 0, 1)
            # ==========================================
            if self.calib_step < 2:
                # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ í™”ë©´ í‘œì‹œ ë° ì²˜ë¦¬
                if self.calib_step == 0:
                    msg_text = "Click TOP edge" if self.temp_pt is None else "Click BOTTOM edge"
                    cv2.putText(cv_image, "[STEP 1] Height Vector", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                    cv2.putText(cv_image, msg_text, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                elif self.calib_step == 1:
                    # 4ì  í´ë¦­ ë‹¨ê³„
                    msg_text = f"Click TOP: {self.click_order[len(self.clicked_points)]}" if len(self.clicked_points) < 4 else "Computing..."
                    cv2.putText(cv_image, "[STEP 2] 4-Point Homography", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
                    cv2.putText(cv_image, msg_text, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                    # 4ì  ì°ì—ˆìœ¼ë©´ í–‰ë ¬ ê³„ì‚° ( Assertion Error ë°©ì§€ ë¡œì§ í¬í•¨)
                    if len(self.clicked_points) == 4:
                        src_pts_list = np.float32(self.clicked_points)
                        
                        # [ASSERTION CHECK] í–‰ë ¬ í¬ê¸° ê²€ì¦ (ê°€ì¥ ì¤‘ìš”)
                        if src_pts_list.shape == (4, 2) and self.dst_points.shape == (4, 2):
                            # [í•µì‹¬] ë†’ì´ ë³´ì • ì ìš© (ë°”ë‹¥ ì¢Œí‘œ ê³„ì‚°)
                            bottom_pts = src_pts_list + self.height_vector
                            
                            self.homography_matrix = cv2.getPerspectiveTransform(bottom_pts, self.dst_points)
                            self.calib_step = 2
                            self.get_logger().info("âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ! YOLO ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                        else:
                            self.get_logger().error(f"âŒ ì¢Œí‘œ ê°œìˆ˜ ì˜¤ë¥˜! {src_pts_list.shape[0]}ì . ë¦¬ì…‹í•©ë‹ˆë‹¤.")
                            self.clicked_points = []
                            self.temp_pt = None
                            self.calib_step = 0 # ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘

                    # ì°ì€ ì ê³¼ ì˜ˆìƒ ë°”ë‹¥ ìœ„ì¹˜ ì‹œê°í™”
                    for pt in self.clicked_points:
                        cv2.circle(cv_image, (pt[0], pt[1]), 5, (0, 255, 255), -1) # ìœ—ë©´ (ë…¸ë‘)
                        bottom_x = int(pt[0] + self.height_vector[0])
                        bottom_y = int(pt[1] + self.height_vector[1])
                        cv2.circle(cv_image, (bottom_x, bottom_y), 3, (0, 255, 0), -1) # ë°”ë‹¥ (ì´ˆë¡)

                # í™”ë©´ ì¶œë ¥ ë° ë§ˆìš°ìŠ¤ ì½œë°± ì—°ê²°
                cv2.imshow(self.cv_window_name, cv_image)
                cv2.setMouseCallback(self.cv_window_name, self.mouse_callback)
                
                # í‚¤ ì…ë ¥ í™•ì¸ (R ëˆ„ë¥´ë©´ ë¦¬ì…‹)
                key = cv2.waitKey(1) & 0xFF
                if key == ord('r') or key == ord('R'):
                    self.clicked_points = []
                    self.temp_pt = None
                    self.calib_step = 0
                    self.get_logger().info("ğŸ”„ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì°ì–´ì£¼ì„¸ìš”.")
                return # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤‘ì—ëŠ” YOLO ì‹¤í–‰ ì•ˆ í•¨

            # ==========================================
            # ëª¨ë“œ 2: YOLO ì‹¤í–‰ ë° ì¢Œí‘œ ë³€í™˜ (calib_step == 2)
            # ==========================================
            else:
                self.frame_count += 1
                if self.frame_count % self.skip_frames != 0:
                    return
                
                results = self.model(cv_image, verbose=False, conf=0.5, imgsz=320)
                annotated_image = results[0].plot()
                car_detected = False

                for i, box in enumerate(results[0].boxes):
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    label = self.model.names[int(box.cls[0])]
                    if label == 'car': car_detected = True

                    # ì¤‘ì‹¬ì  (í”½ì…€)
                    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
                    
                    # ë§µ ì¢Œí‘œ ë³€í™˜ (Homography)
                    px = np.array([[[cx, cy]]], dtype=np.float32)
                    dst = cv2.perspectiveTransform(px, self.homography_matrix)
                    map_x, map_y = dst[0][0][0], dst[0][0][1]

                    # 1. PointStamped (RViz ì§€ë„ í‘œì‹œ)
                    ps_msg = PointStamped()
                    ps_msg.header.stamp = self.get_clock().now().to_msg()
                    ps_msg.header.frame_id = "map"  
                    ps_msg.point.x, ps_msg.point.y = float(map_x), float(map_y)
                    self.map_point_pub.publish(ps_msg)

                    # 2. Marker (RViz ì‹œê°í™”)
                    marker = Marker()
                    marker.header = ps_msg.header
                    marker.ns = "yolo_objects"
                    marker.id = i
                    marker.type = Marker.SPHERE
                    marker.action = Marker.ADD
                    marker.pose.position.x, marker.pose.position.y, marker.pose.position.z = float(map_x), float(map_y), 0.0
                    marker.scale.x, marker.scale.y, marker.scale.z = 0.2, 0.2, 0.2
                    marker.color.a = 1.0; marker.color.r = 1.0; marker.color.g = 0.0; marker.color.b = 0.0
                    self.marker_pub.publish(marker)

                    # 3. ë¡œê·¸ ë° ì´ë¯¸ì§€ ì‹œê°í™”
                    cv2.putText(annotated_image, f"({map_x:.2f}, {map_y:.2f})m", 
                               (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
                    self.get_logger().info(f"ğŸ“ {label} -> Map({map_x:.2f}, {map_y:.2f})")

                self.car_pub.publish(Bool(data=car_detected))
                self.image_pub.publish(self.bridge.cv2_to_imgmsg(annotated_image, "bgr8"))
                
                cv2.imshow(self.cv_window_name, annotated_image)
                
                if cv2.waitKey(1) & 0xFF == ord('r'):
                    self.calib_step = 0
                    self.clicked_points = []
                    self.temp_pt = None

        except Exception as e:
            self.get_logger().error(f"FATAL ERROR: {e}")

def main(args=None):
    rclpy.init(args=args)
    node = YoloMapTransformNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()
        cv2.destroyAllWindows()

if __name__ == '__main__':
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìœˆë„ìš°ê°€ ë©”ì¸ í•¨ìˆ˜ì—ì„œ ìƒì„±ë˜ì–´ì•¼ í•˜ë¯€ë¡œ ì´ ì½”ë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    main()