
import rclpy
from rclpy.node import Node

from sensor_msgs.msg import CompressedImage, Image
from geometry_msgs.msg import Twist
from std_msgs.msg import String, Bool

from cv_bridge import CvBridge
import cv2
import numpy as np

import math
import time
import json
from rclpy.qos import QoSProfile, QoSReliabilityPolicy, QoSHistoryPolicy

from rclpy.executors import MultiThreadedExecutor
from rclpy.callback_groups import ReentrantCallbackGroup

# TurtleBot4 Nav2 helper
from turtlebot4_navigation.turtlebot4_navigator import (
    TurtleBot4Navigator,
    TurtleBot4Directions,
)


class OrientationConverter:
    """ë°©í–¥ ë³€í™˜ ìœ í‹¸ë¦¬í‹°"""
    DIRECTION_MAP = {
        'NORTH': TurtleBot4Directions.NORTH,
        'SOUTH': TurtleBot4Directions.SOUTH,
        'EAST': TurtleBot4Directions.EAST,
        'WEST': TurtleBot4Directions.WEST,
    }
    
    @classmethod
    def to_turtlebot_direction(cls, orientation_str: str) -> float:
        return cls.DIRECTION_MAP.get(orientation_str.upper(), TurtleBot4Directions.NORTH)


class ParkingOrchestrator(Node):
    def __init__(self):
        super().__init__("parking_orchestrator")

        self.bridge = CvBridge()
        self.reentrant_group = ReentrantCallbackGroup()
        # ==================== ìƒíƒœ ê´€ë¦¬ ====================
        self.state = "WAITING_ALLOCATION"  # WAITING_ALLOCATION, NAVIGATING, LINE_DETECT, DONE
        self.current_allocation = None
        self.enable_line_detect = False
        
        # ==================== Parameters ====================
        self.declare_parameter("image_topic", "/robot1/oakd/rgb/image_raw/compressed")
        self.declare_parameter("cmd_vel_topic", "/robot1/cmd_vel")
        self.declare_parameter("kp_angular", 0.003)
        self.declare_parameter("align_linear_speed", 0.05)
        self.declare_parameter("final_forward_speed", 0.08)
        self.declare_parameter("final_forward_distance", 0.2)

        image_topic = self.get_parameter("image_topic").value
        cmd_vel_topic = self.get_parameter("cmd_vel_topic").value

        self.kp_ang = self.get_parameter("kp_angular").value
        self.align_linear_speed = self.get_parameter("align_linear_speed").value
        self.final_forward_speed = self.get_parameter("final_forward_speed").value
        self.final_forward_distance = self.get_parameter("final_forward_distance").value

        if self.final_forward_speed > 0.0:
            self.final_forward_duration = self.final_forward_distance / self.final_forward_speed
        else:
            self.final_forward_duration = 0.0

        # ==================== QoS ====================
        sensor_qos = QoSProfile(
            reliability=QoSReliabilityPolicy.BEST_EFFORT,
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=10
        )
        
        reliable_qos = QoSProfile(
            reliability=QoSReliabilityPolicy.RELIABLE,
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=10
        )

        # ì£¼ì°¨ í• ë‹¹ ê²°ê³¼ êµ¬ë…
        self.allocation_sub = self.create_subscription(
            String,
            '/parking_allocation',
            self.allocation_callback,
            10,
            callback_group=self.reentrant_group
        )
        
        # ì´ë¯¸ì§€ êµ¬ë…
        self.image_sub = self.create_subscription(
            CompressedImage,
            image_topic,
            self.image_callback,
            sensor_qos
        )

        # cmd_vel ë°œí–‰
        self.cmd_pub = self.create_publisher(Twist, cmd_vel_topic, 10)

        # ì£¼ì°¨ ì™„ë£Œ ì‹ í˜¸ ë°œí–‰
        self.parking_done_pub = self.create_publisher(
            Bool,
            '/parking_done',
            10
        )

        # ë””ë²„ê·¸ ì´ë¯¸ì§€
        self.debug_image_pub = self.create_publisher(
            Image,
            "/line_center/debug_image",
            reliable_qos
        )

        # ==================== Navigator ====================
        self.navigator = TurtleBot4Navigator()

        # ==================== ë¼ì¸ ê²€ì¶œ ë³€ìˆ˜ ====================
        # ë””ë²„ê·¸ ìš©
        self.callback_count = 0
        self.last_callback_time = None

        # ì •ë ¬ íŠœë‹ íŒŒë¼ë¯¸í„°
        self.dead_band_px = 5.0
        self.center_tolerance_px = 15.0
        self.max_angular_z = 0.5
        self.stable_needed = 5
        self.stable_count = 0

        # Phase ìƒíƒœ
        self.phase = "ALIGN_MOVE"
        self.phase3_start_time = None
        self.scan_start_time = None

        self.get_logger().info("ğŸš— Parking Orchestrator ì‹œì‘!")
        self.get_logger().info("â³ ì£¼ì°¨ ê³µê°„ í• ë‹¹ ëŒ€ê¸° ì¤‘...")
        
        # íƒ€ì´ë¨¸
        self.create_timer(2.0, self.status_check)

    def allocation_callback(self, msg: String):

        if self.state != "WAITING_ALLOCATION":
            return
        
        try:
            data = json.loads(msg.data)
            
            if not data['success']:
                self.get_logger().error(f"âŒ ì£¼ì°¨ í• ë‹¹ ì‹¤íŒ¨: {data['message']}")
                return
            
            self.current_allocation = data
            
            self.get_logger().info(f"\n{'='*60}")
            self.get_logger().info(f"âœ… ì£¼ì°¨ ê³µê°„ í• ë‹¹ë¨!")
            self.get_logger().info(f"   ìœ„ì¹˜: {data['location_id']}")
            self.get_logger().info(f"   Zone: {data['zone_id']}")
            self.get_logger().info(f"   ì¢Œí‘œ: ({data['x']}, {data['y']})")
            self.get_logger().info(f"   ë°©í–¥: {data['orientation']}")
            self.get_logger().info(f"{'='*60}\n")
            
            # Navigation ì‹œì‘
            self.state = "NAVIGATING"
            self.navigate_to_zone()
            
        except Exception as e:
            self.get_logger().error(f"âŒ í• ë‹¹ ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    def navigate_to_zone(self):
        """Nav2ë¡œ Zone ì¢Œí‘œ ì´ë™"""
        if not self.current_allocation:
            return
        
        allocation = self.current_allocation
        
        target_x = allocation['x']
        target_y = allocation['y']
        
        # Orientation ë³€í™˜
        orientation_str = allocation['orientation']
        target_yaw = OrientationConverter.to_turtlebot_direction(orientation_str)
        
        self.get_logger().info(f"\n{'='*60}")
        self.get_logger().info(f"ğŸš€ Navigation ì‹œì‘")
        self.get_logger().info(f"   ëª©í‘œ: ({target_x:.2f}, {target_y:.2f})")
        self.get_logger().info(f"   ë°©í–¥: {orientation_str}")
        self.get_logger().info(f"{'='*60}\n")
        
        # Undocking (í•„ìš”ì‹œ)
        if self.navigator.getDockedStatus():
            self.get_logger().info("ğŸ“ Undocking...")
            self.navigator.undock()
            time.sleep(2)
        
        # Navigation ì‹¤í–‰
        success = self.navigate_to_goal(target_x, target_y, target_yaw)
        
        if success:
            self.get_logger().info("âœ… Zone ë„ì°©! ë¼ì¸ ì •ë ¬ ì‹œì‘")
            self.state = "LINE_DETECT"
            self.enable_line_detect = True
        else:
            self.get_logger().error("âŒ Navigation ì‹¤íŒ¨")
            self.state = "WAITING_ALLOCATION"

    def navigate_to_goal(self, target_x: float, target_y: float, target_yaw: float) -> bool:
        """Nav2ë¡œ ëª©í‘œ ì§€ì  ì´ë™"""
        try:
            self.get_logger().info("â³ Nav2 í™œì„±í™” ëŒ€ê¸°...")
            self.navigator.waitUntilNav2Active()
            
            goal_pose = self.navigator.getPoseStamped([target_x, target_y], target_yaw)
            
            self.get_logger().info(f"ğŸ¯ ëª©í‘œ: ({target_x:.2f}, {target_y:.2f})")
            self.navigator.goToPose(goal_pose)
            
            start_time = time.time()
            timeout = 180
            
            while not self.navigator.isTaskComplete():
                elapsed = time.time() - start_time
                if elapsed > timeout:
                    self.get_logger().error("âŒ íƒ€ì„ì•„ì›ƒ!")
                    self.navigator.cancelTask()
                    return False
                time.sleep(0.5)
            
            self.get_logger().info("âœ… ì´ë™ ì™„ë£Œ!")
            return True
            
        except Exception as e:
            self.get_logger().error(f"âŒ Navigation ì˜¤ë¥˜: {e}")
            return False

    def status_check(self):
        """ì£¼ê¸°ì  ìƒíƒœ ì²´í¬"""
        current_time = self.get_clock().now()
        
        if self.last_callback_time is not None:
            interval = (current_time - self.last_callback_time).nanoseconds / 1e9
            fps = 1.0 / interval if interval > 0 else 0.0
        else:
            fps = 0.0
        
        self.get_logger().info(
            f"[ìƒíƒœ] State={self.state}, Phase={self.phase}, "
            f"ì½œë°±={self.callback_count}íšŒ, FPS={fps:.1f}"
        )

    def image_callback(self, msg: CompressedImage):
        """ì´ë¯¸ì§€ ì½œë°± - ë¼ì¸ ê²€ì¶œ"""
        if not self.enable_line_detect:
            return
        
        self.callback_count += 1
        self.last_callback_time = self.get_clock().now()
        
        if self.callback_count <= 3:
            self.get_logger().info(f"âœ… image_callback í˜¸ì¶œ! (#{self.callback_count})")
        
        cmd = Twist()

        if self.phase == "DONE":
            self.cmd_pub.publish(cmd)
            return

        # 1) CompressedImage -> OpenCV BGR
        try:
            frame = self.bridge.compressed_imgmsg_to_cv2(msg, desired_encoding="bgr8")
        except Exception as e:
            self.get_logger().error(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            return

        h, w, _ = frame.shape

        # 2) ROI ì„¤ì •
        roi_y_start = int(h * 2 / 3)
        roi = frame[roi_y_start:h, :]

        # 3) í° ì„  ê²€ì¶œ (HSV í•„í„°)
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        
        lower_white = np.array([0, 0, 200], dtype=np.uint8)
        upper_white = np.array([179, 30, 255], dtype=np.uint8)
        mask_white = cv2.inRange(hsv, lower_white, upper_white)

        # 4) ë…¸ì´ì¦ˆ ì œê±°
        kernel = np.ones((5, 5), np.uint8)
        mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_OPEN, kernel)
        mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_CLOSE, kernel)

        # 5) ì»¨íˆ¬ì–´ ì°¾ê¸°
        contours, _ = cv2.findContours(
            mask_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        line_found = False
        lane_center_x = None

        if contours:
            min_area = 300.0
            min_aspect = 2.0

            candidates = []
            for c in contours:
                area = cv2.contourArea(c)
                if area < min_area: continue

                x, y, cw, ch = cv2.boundingRect(c)
                aspect = ch / float(cw + 1e-3)
                if aspect < min_aspect: continue

                candidates.append((area, c))

            if candidates:
                image_center_x = w / 2.0
                best_c = None
                min_distance_to_center = float('inf')

                for area, c in candidates:
                    M = cv2.moments(c)
                    if M["m00"] > 0:
                        cx = M["m10"] / M["m00"]
                        dist = abs(cx - image_center_x)
                        if dist < min_distance_to_center:
                            min_distance_to_center = dist
                            best_c = c

                if best_c is not None:
                    M = cv2.moments(best_c)
                    if M["m00"] > 0:
                        cx_global = (M["m10"] / M["m00"])
                        cy_global = (M["m01"] / M["m00"]) + roi_y_start

                        x, y, cw, ch = cv2.boundingRect(best_c)
                        cv2.rectangle(frame, (x, y + roi_y_start), (x + cw, y + ch + roi_y_start), (0, 255, 0), 2)
                        cv2.circle(frame, (int(cx_global), int(cy_global)), 5, (0, 0, 255), -1)

                        lane_center_x = cx_global
                        line_found = True

        # ---- ì œì–´ ë¡œì§ ----
        if line_found and lane_center_x is not None:
            self.scan_start_time = None

            cv2.line(frame, (int(lane_center_x), roi_y_start), (int(lane_center_x), h), (255, 0, 0), 2)

            image_center_x = w / 2.0
            error_px = lane_center_x - image_center_x

            cv2.putText(frame, f"Phase: {self.phase}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame, f"Error: {error_px:.1f}px", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame, f"Stable: {self.stable_count}/{self.stable_needed}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            raw_omega = -self.kp_ang * error_px
            if raw_omega > self.max_angular_z: raw_omega = self.max_angular_z
            elif raw_omega < -self.max_angular_z: raw_omega = -self.max_angular_z

            if self.phase == "ALIGN_MOVE":
                cmd.linear.x = self.align_linear_speed

                if abs(error_px) < self.dead_band_px:
                    cmd.angular.z = 0.0
                else:
                    cmd.angular.z = float(raw_omega)

                if abs(error_px) < self.center_tolerance_px:
                    self.stable_count += 1
                else:
                    self.stable_count = 0

                if self.stable_count >= self.stable_needed:
                    self.phase = "FINAL_FORWARD"
                    self.phase3_start_time = time.time()
                    self.get_logger().info("âœ… ì •ë ¬ ì™„ë£Œ! ìµœì¢… ì§ì§„ ì‹œì‘")

            elif self.phase == "FINAL_FORWARD":
                elapsed = time.time() - self.phase3_start_time
                cmd.linear.x = self.final_forward_speed
                cmd.angular.z = float(raw_omega)

                if elapsed >= self.final_forward_duration:
                    cmd.linear.x = 0.0
                    cmd.angular.z = 0.0
                    self.phase = "DONE"
                    self.get_logger().info("ğŸ ì£¼ì°¨ ì™„ë£Œ!")
                    
                    # ì£¼ì°¨ ì™„ë£Œ ì‹ í˜¸ ë°œí–‰
                    self.parking_done_pub.publish(Bool(data=True))
                    
                    # ìƒíƒœ ë³€ê²½
                    self.state = "DONE"
                    self.enable_line_detect = False

        else:
            # ë¼ì¸ ë¯¸ê²€ì¶œ
            if self.phase == "ALIGN_MOVE":
                if self.scan_start_time is None:
                    self.scan_start_time = time.time()
                
                elapsed_scan = time.time() - self.scan_start_time
                
                status_text = "SCANNING..."
                if elapsed_scan < 2.0:
                    cmd.angular.z = -0.3
                    status_text = "SCAN: LEFT"
                elif elapsed_scan < 5.0:
                    cmd.angular.z = 0.3
                    status_text = "SCAN: RIGHT"
                elif elapsed_scan < 7.0:
                    cmd.angular.z = -0.3
                    status_text = "SCAN: CENTER"
                else:
                    cmd.angular.z = 0.0
                    status_text = "SCAN: GAVE UP"

                cmd.linear.x = 0.0
                cv2.putText(frame, status_text, (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            else:
                cmd.linear.x = 0.0
                cmd.angular.z = 0.0
            
            cv2.putText(frame, "NO LINE", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        self.cmd_pub.publish(cmd)

        # ë””ë²„ê·¸ ì´ë¯¸ì§€
        try:
            debug_msg = self.bridge.cv2_to_imgmsg(frame, encoding="bgr8")
            debug_msg.header = msg.header
            self.debug_image_pub.publish(debug_msg)
        except Exception as e:
            if self.callback_count <= 3:
                self.get_logger().error(f"ë””ë²„ê·¸ ì´ë¯¸ì§€ ì‹¤íŒ¨: {e}")


def main(args=None):
    print("=== Parking Orchestrator ì‹œì‘ ===")
    rclpy.init(args=args)
    
    orchestrator = ParkingOrchestrator()
    
    # ê¸°ì¡´: rclpy.spin(orchestrator)
    
    # ë³€ê²½: MultiThreadedExecutor ì‚¬ìš©
    executor = MultiThreadedExecutor()
    executor.add_node(orchestrator)
    
    try:
        executor.spin()
    except KeyboardInterrupt:
        orchestrator.get_logger().info("ì¢…ë£Œ")
    finally:
        orchestrator.destroy_node()
        cv2.destroyAllWindows()
        rclpy.shutdown()

if __name__ == "__main__":
    main()