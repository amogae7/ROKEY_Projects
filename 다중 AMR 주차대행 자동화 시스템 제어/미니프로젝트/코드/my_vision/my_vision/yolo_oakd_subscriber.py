#!/usr/bin/env python3
"""
TurtleBot Oak-D ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ êµ¬ë…í•˜ì—¬ YOLO ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë…¸ë“œ
ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ê³„ì‚°í•˜ê³  publish
"""

from ultralytics import YOLO
import cv2
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String, Bool, Float32
from geometry_msgs.msg import Point
from cv_bridge import CvBridge
import json


class YoloOakdSubscriber(Node):
    def __init__(self):
        super().__init__('yolo_oakd_subscriber')

        # --- ROS íŒŒë¼ë¯¸í„° ---
        self.declare_parameter('robot_name', 'robot5')
        self.declare_parameter('model_path', 'best.pt')
        self.declare_parameter('use_preview', True)
        self.declare_parameter('topic_annotated', 'yolo/image_annotated')
        self.declare_parameter('topic_result', 'yolo/result_text')
        self.declare_parameter('topic_centers', 'yolo/bbox_centers')  # ìƒˆë¡œìš´ í† í”½
        self.declare_parameter('confidence', 0.5)
        self.declare_parameter('draw_center', True)  # ì¤‘ì‹¬ì  ê·¸ë¦¬ê¸° ì˜µì…˜

        robot_name = self.get_parameter('robot_name').value
        model_path = self.get_parameter('model_path').value
        use_preview = self.get_parameter('use_preview').value
        topic_annotated = self.get_parameter('topic_annotated').value
        topic_result = self.get_parameter('topic_result').value
        topic_centers = self.get_parameter('topic_centers').value
        self.confidence = self.get_parameter('confidence').value
        self.draw_center = self.get_parameter('draw_center').value
        self.declare_parameter('topic_trigger', 'yolo/center_trigger')
        topic_trigger = self.get_parameter('topic_trigger').value

        self.pub_trigger = self.create_publisher(Bool, topic_trigger, 10)
        self.get_logger().info(f'ğŸ”” Center trigger will be published to: {topic_trigger}')
        self.pub_amr_detected = self.create_publisher(String, '/amr_car_detected', 10)
        self.get_logger().info("ğŸ“¡ /amr_car_detected: center aligned car signal will be published when centered.")

        # ğŸ”¹ xì¶• ì˜¤ì°¨ íŠœë‹ìš© í¼ë¸”ë¦¬ì…” (ì™¼ìª½ + / ì˜¤ë¥¸ìª½ -)
        self.pub_x_error = self.create_publisher(Float32, 'x_error_for_tuning', 10)
        self.get_logger().info("ğŸ“ /x_error_for_tuning: x-axis error (pixels) will be published for tuning.")

        # ğŸ”¹ car ë°•ìŠ¤ ê°€ë¡œê¸¸ì´ í¼ë¸”ë¦¬ì…” (px)
        self.pub_bbox_width = self.create_publisher(Float32, 'bbox_width_for_tuning', 10)
        self.get_logger().info("ğŸ“ /bbox_width_for_tuning: car bbox width (pixels) will be published.")

        



        # ì¹´ë©”ë¼ í† í”½ ì„ íƒ
        if use_preview:
            camera_topic = f'/{robot_name}/oakd/rgb/preview/image_raw' 
            self.get_logger().info('Using preview image (ë‚®ì€ í•´ìƒë„, ë¹ ë¦„)')
        else:
            camera_topic = f'/{robot_name}/oakd/rgb/image_raw'
            self.get_logger().info('Using full resolution image (ê³ í•´ìƒë„, ëŠë¦¼)')

        self.get_logger().info(f'Subscribing to: {camera_topic}')
        self.get_logger().info(f'Loading YOLO model: {model_path}')

        # --- YOLO ëª¨ë¸ ë¡œë“œ ---
        try:
            self.model = YOLO(model_path)
            self.get_logger().info('âœ… YOLO model loaded successfully!')
        except Exception as e:
            self.get_logger().error(f'âŒ Failed to load YOLO model: {e}')
            raise

        # --- Subscriber ì„¤ì • ---
        self.bridge = CvBridge()
        self.subscription = self.create_subscription(
            Image,
            camera_topic,
            self.image_callback,
            10
        )

        # --- Publisher ì„¤ì • ---
        self.pub_annotated = self.create_publisher(Image, topic_annotated, 10)
        self.pub_result = self.create_publisher(String, topic_result, 10)
        self.pub_centers = self.create_publisher(String, topic_centers, 10)  # ì¤‘ì‹¬ ì¢Œí‘œ

        self.get_logger().info('ğŸš€ Node started! Waiting for images...')
        self.get_logger().info(f'ğŸ“ Publishing bbox centers to: {topic_centers}')

    def image_callback(self, msg):
        """ì´ë¯¸ì§€ í† í”½ì„ ë°›ì•„ì„œ YOLO ì¶”ë¡  ì‹¤í–‰"""
        try:
            # 1. ROS Image â†’ OpenCV ì´ë¯¸ì§€ ë³€í™˜
            frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')

            h, w = frame.shape[:2]
            image_center_x = w // 2

            # ì¤‘ì•™ ë¼ì¸ ì£¼ë³€ í—ˆìš© ë²”ìœ„ (ì˜ˆ: ì „ì²´ í­ì˜ 5%)
            center_band = int(w * 0.10) 

            # ğŸ”¹ ìœ„ìª½ ë¬´ì‹œ ë¹„ìœ¨ (ì˜ˆ: ìƒë‹¨ 30%ëŠ” ë¬´ì‹œ)
            ignore_top_ratio = 0.4
            ignore_top = int(h * ignore_top_ratio)


            # 2. YOLO ì¶”ë¡ 
            results = self.model(frame, conf=self.confidence, verbose=False)
            res = results[0]

            # 3. íƒì§€ ê²°ê³¼ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ ìƒì„±
            annotated_frame = res.plot()
            
            # 4. ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚° ë° ê·¸ë¦¬ê¸°
            names = res.names
            boxes = res.boxes
            
            detection_data = []  # íƒì§€ ê²°ê³¼ ì €ì¥
            trigger = False

            # ğŸ”¹ car ì¤‘ì—ì„œ ê°€ì¥ ê°€ìš´ë°ì— ê°€ê¹Œìš´ ê²ƒ ê¸°ì¤€ìœ¼ë¡œ x_error ê³„ì‚°
            best_x_error = None     # ì‹¤ì œ ì˜¤ì°¨ ê°’ (ì™¼ìª½ + / ì˜¤ë¥¸ìª½ -)
            best_abs_error = None   # |ì˜¤ì°¨| (ê°€ìš´ë°ì—ì„œ ì–¼ë§ˆë‚˜ ë¨¼ì§€)
            best_width = None
            # ===========================================


            h, w = frame.shape[:2]
            image_center_x = w // 2

            

            # ====== ğŸ” ì„¼í„° ë°´ë“œ ì‹œê°í™” ì¶”ê°€ ë¶€ë¶„ ======
            left_bound  = image_center_x - center_band
            right_bound = image_center_x + center_band

            # ì¸ë±ìŠ¤ ë²”ìœ„ ë³´ì •
            left_bound  = max(0, left_bound)
            right_bound = min(w - 1, right_bound)

            # ë°˜íˆ¬ëª… ë°•ìŠ¤ë¡œ ê°€ìš´ë° ì˜ì—­ í‘œì‹œ
            overlay = annotated_frame.copy()
            cv2.rectangle(
                overlay,
                (left_bound, 0),
                (right_bound, h - 1),
                (255, 0, 0),     # íŒŒë€ìƒ‰ ì˜ì—­ (BGR)
                -1               # ì±„ìš°ê¸°
            )
            alpha = 0.2  # íˆ¬ëª…ë„
            annotated_frame = cv2.addWeighted(overlay, alpha, annotated_frame, 1 - alpha, 0)

            # ì¤‘ì•™ì„ (ì •í™•í•œ center_x)ë„ í°ìƒ‰ ì„ ìœ¼ë¡œ í•œë²ˆ ë” í‘œì‹œ
            cv2.line(
                annotated_frame,
                (image_center_x, 0),
                (image_center_x, h - 1),
                (255, 255, 255),  # í°ìƒ‰
                1
            )

            # if boxes is not None and len(boxes) > 0:
            #     for box in boxes:
            #         # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
            #         x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
            #         # ì¤‘ì‹¬ ì¢Œí‘œ ê³„ì‚°
            #         center_x = int((x1 + x2) / 2)
            #         center_y = int((y1 + y2) / 2)
                    
            #         # í´ë˜ìŠ¤ ì •ë³´
            #         class_id = int(box.cls[0])
            #         class_name = names[class_id]
            #         confidence = float(box.conf[0])
                    
            #         # ë°ì´í„° ì €ì¥
            #         detection_data.append({
            #             'class': class_name,
            #             'confidence': round(confidence, 2),
            #             'bbox': {
            #                 'x1': int(x1), 'y1': int(y1),
            #                 'x2': int(x2), 'y2': int(y2)
            #             },
            #             'center': {
            #                 'x': center_x,
            #                 'y': center_y
            #             }
            #         })
                    
            #         # ì´ë¯¸ì§€ì— ì¤‘ì‹¬ì  ê·¸ë¦¬ê¸°
            #         if self.draw_center:
            #             # ì¤‘ì‹¬ì  í‘œì‹œ (ë¹¨ê°„ ì›)
            #             cv2.circle(annotated_frame, (center_x, center_y), 5, (0, 0, 255), -1)
                        
            #             # ì‹­ìì„  í‘œì‹œ
            #             cv2.line(annotated_frame, 
            #                     (center_x - 10, center_y), 
            #                     (center_x + 10, center_y), 
            #                     (0, 0, 255), 2)
            #             cv2.line(annotated_frame, 
            #                     (center_x, center_y - 10), 
            #                     (center_x, center_y + 10), 
            #                     (0, 0, 255), 2)
                        
            #             # ì¢Œí‘œ í…ìŠ¤íŠ¸ í‘œì‹œ
            #             coord_text = f"({center_x}, {center_y})"
            #             cv2.putText(annotated_frame, coord_text, 
            #                        (center_x + 15, center_y - 15),
            #                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

            if boxes is not None and len(boxes) > 0:
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    center_x = int((x1 + x2) / 2)
                    center_y = int((y1 + y2) / 2)

                    class_id = int(box.cls[0])
                    class_name = names[class_id]
                    confidence = float(box.conf[0])

                    if class_name != 'car':
                        continue

                    # ğŸ”¹ ìœ„ìª½ ì˜ì—­(ìƒë‹¨ 30%)ì— ìˆëŠ” ë°•ìŠ¤ëŠ” ë¬´ì‹œ
                    if center_y < ignore_top:
                        continue

                    width_px = float(x2 - x1)

                    # ì¤‘ì•™ì„ ì— ë“¤ì–´ì™”ëŠ”ì§€ íŒë‹¨ (x ì¢Œí‘œ ê¸°ì¤€)
                    if abs(center_x - image_center_x) <= center_band:
                        trigger = True
                        self.get_logger().info(
                            f"ğŸ¯ {class_name} center aligned with vertical center line: "
                            f"center_x={center_x}, image_center_x={image_center_x}"
                        )

                    x_error = image_center_x - center_x          # px ë‹¨ìœ„
                    abs_error = abs(x_error)

                    # car ì¤‘ì—ì„œ ê°€ì¥ ê°€ìš´ë°ì— ê°€ê¹Œìš´ ê²ƒ ì„ íƒ
                    if best_abs_error is None or abs_error < best_abs_error:
                        best_abs_error = abs_error
                        best_x_error = x_error
                        best_width = width_px

                    detection_data.append({
                        'class': class_name,
                        'confidence': round(confidence, 2),
                        'bbox': {
                            'x1': int(x1), 'y1': int(y1),
                            'x2': int(x2), 'y2': int(y2)
                        },
                        'center': {
                            'x': center_x,
                            'y': center_y
                        }
                    })

                    # (ê¸°ì¡´ ì¤‘ì‹¬ì  ê·¸ë¦¬ê¸° ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€)
                    if self.draw_center:
                        cv2.circle(annotated_frame, (center_x, center_y), 5, (0, 0, 255), -1)
                        cv2.line(annotated_frame, (center_x - 10, center_y),
                                (center_x + 10, center_y), (0, 0, 255), 2)
                        cv2.line(annotated_frame, (center_x, center_y - 10),
                                (center_x, center_y + 10), (0, 0, 255), 2)
                        coord_text = f"({center_x}, {center_y})"
                        cv2.putText(annotated_frame, coord_text,
                                    (center_x + 15, center_y - 15),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                
                # ë¡œê·¸ ì¶œë ¥
                for det in detection_data:
                    self.get_logger().info(
                        f"ğŸ“ {det['class']}({det['confidence']}) - "
                        f"Center: ({det['center']['x']}, {det['center']['y']})"
                    )

                # ğŸ”¹ car ê¸°ì¤€ x_error_for_tuning publish
                if best_x_error is not None:
                    err_msg = Float32()
                    err_msg.data = float(best_x_error)
                    self.pub_x_error.publish(err_msg)

                    self.get_logger().info(
                        f"ğŸ“ x_error_for_tuning: {err_msg.data:.1f} px (left + / right -)"
                    )

                # ğŸ”¹ bbox_width_for_tuning publish (car ì¤‘ ê°€ì¥ ê°€ìš´ë°ì— ê°€ê¹Œìš´ ë°•ìŠ¤ì˜ ê°€ë¡œê¸¸ì´)
                if best_width is not None:
                    w_msg = Float32()
                    w_msg.data = float(best_width)
                    self.pub_bbox_width.publish(w_msg)
                    self.get_logger().info(
                        f"ğŸ“ bbox_width_for_tuning: {w_msg.data:.1f} px (preview frame ê¸°ì¤€)"
                    )
            
            # 5. ì¤‘ì‹¬ ì¢Œí‘œ ë°ì´í„° publish (JSON í˜•íƒœ)
            centers_msg = String()
            centers_msg.data = json.dumps(detection_data, indent=2)
            self.pub_centers.publish(centers_msg)
            
            # 6. íƒì§€ ê²°ê³¼ ì´ë¯¸ì§€ publish
            msg_annotated = self.bridge.cv2_to_imgmsg(
                annotated_frame, encoding='bgr8'
            )
            msg_annotated.header = msg.header
            self.pub_annotated.publish(msg_annotated)

            # 7. ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê²°ê³¼ publish
            if detection_data:
                detection_list = [f"{d['class']}({d['confidence']})" for d in detection_data]
                text = f"Detected: {', '.join(detection_list)}"
            else:
                text = "Detected: none"

            msg_result = String()
            msg_result.data = text
            self.pub_result.publish(msg_result)

            # 8. ì¤‘ì•™ì— ìˆì„ ë•Œë§Œ /amr_car_detected í† í”½ ì†¡ì‹  (ì—†ìœ¼ë©´ ì•„ë¬´ ê²ƒë„ ì•ˆ ë³´ëƒ„)
            if trigger:
                trigger_msg = String()
                trigger_msg.data = "center_detected"
                self.pub_amr_detected.publish(trigger_msg)
            

        except Exception as e:
            self.get_logger().error(f'Error in image_callback: {e}')

    def destroy_node(self):
        self.get_logger().info('Shutting down YOLO node...')
        super().destroy_node()


def main(args=None):
    rclpy.init(args=args)
    node = YoloOakdSubscriber()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()